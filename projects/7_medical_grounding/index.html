<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="robots" content="noindex, nofollow, noarchive, nosnippet"> <title> Medical Image Grounding | Junzhi (Raymond) Ning </title> <meta name="author" content="Junzhi (Raymond) Ning"> <meta name="description" content="Spatial-Semantic Rewarded Group Relative Policy Optimization"> <meta name="keywords" content="machine-learning, medical-imaging, artificial-intelligence, computer-vision, deep-learning"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/optimized_solution.jpg?ca2ddf899b29608d36c5260cf0b4a94a"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://junzhin.github.io/projects/7_medical_grounding/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Junzhi</span> (Raymond) Ning </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Medical Image Grounding</h1> <p class="post-description">Spatial-Semantic Rewarded Group Relative Policy Optimization</p> </header> <article> <h2 id="overview">Overview</h2> <p>This collaborative research project advances <strong>medical image grounding</strong> through a novel <strong>Spatial-Semantic Rewarded Group Relative Policy Optimization</strong> approach. The work addresses the critical challenge of accurately localizing and interpreting specific anatomical structures and pathological findings in medical images based on textual descriptions.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/spatial_reward_r1_cxr-480.webp 480w,/assets/img/spatial_reward_r1_cxr-800.webp 800w,/assets/img/spatial_reward_r1_cxr-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/spatial_reward_r1_cxr.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Spatial-Semantic Framework" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Spatial-semantic reward framework for medical image grounding </div> <h2 id="research-problem">Research Problem</h2> <h3 id="medical-image-grounding-challenges">Medical Image Grounding Challenges</h3> <p>Medical image grounding involves:</p> <ul> <li> <strong>Precise Localization</strong>: Identifying exact spatial locations of medical findings</li> <li> <strong>Semantic Understanding</strong>: Connecting textual descriptions with visual features</li> <li> <strong>Clinical Accuracy</strong>: Ensuring medically relevant and accurate interpretations</li> <li> <strong>Multi-scale Analysis</strong>: Handling findings at different spatial scales</li> </ul> <h3 id="traditional-limitations">Traditional Limitations</h3> <p>Existing approaches suffer from:</p> <ul> <li> <strong>Imprecise Localization</strong>: Difficulty in pinpointing exact anatomical regions</li> <li> <strong>Semantic Gaps</strong>: Misalignment between textual descriptions and visual features</li> <li> <strong>Limited Clinical Validation</strong>: Lack of medical expert verification</li> <li> <strong>Scale Sensitivity</strong>: Poor performance on multi-scale pathological findings</li> </ul> <h2 id="technical-innovation">Technical Innovation</h2> <h3 id="spatial-semantic-reward-system">Spatial-Semantic Reward System</h3> <p>Our approach introduces a sophisticated reward mechanism that considers:</p> <ol> <li> <strong>Spatial Accuracy</strong>: Precise localization rewards based on ground truth annotations</li> <li> <strong>Semantic Consistency</strong>: Alignment between textual descriptions and visual features</li> <li> <strong>Clinical Relevance</strong>: Medical expert-validated reward signals</li> <li> <strong>Group Coherence</strong>: Consistency across related medical findings</li> </ol> <h3 id="group-relative-policy-optimization">Group Relative Policy Optimization</h3> <p>The <strong>Group Relative Policy Optimization</strong> framework:</p> <ul> <li> <strong>Groups Related Findings</strong>: Clusters similar pathological patterns</li> <li> <strong>Relative Ranking</strong>: Learns comparative relationships between different findings</li> <li> <strong>Policy Gradient Learning</strong>: Optimizes localization policies through reinforcement learning</li> <li> <strong>Multi-objective Optimization</strong>: Balances multiple clinical objectives</li> </ul> <h2 id="methodology">Methodology</h2> <h3 id="multi-modal-architecture">Multi-Modal Architecture</h3> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/9-480.webp 480w,/assets/img/9-800.webp 800w,/assets/img/9-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/9.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Visual Encoder" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/10-480.webp 480w,/assets/img/10-800.webp 800w,/assets/img/10-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/10.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Text Encoder" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11-480.webp 480w,/assets/img/11-800.webp 800w,/assets/img/11-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Grounding Results" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Multi-modal architecture components: visual encoding, text processing, and grounding results </div> <h3 id="training-strategy">Training Strategy</h3> <ol> <li> <strong>Pre-training Phase</strong>: Large-scale medical image-text pair learning</li> <li> <strong>Reward Modeling</strong>: Clinical expert annotation for reward signal design</li> <li> <strong>Policy Learning</strong>: Reinforcement learning for optimal grounding policies</li> <li> <strong>Fine-tuning</strong>: Domain-specific adaptation for different medical specialties</li> </ol> <h2 id="key-contributions">Key Contributions</h2> <h3 id="technical-contributions">Technical Contributions</h3> <ul> <li> <strong>Novel Reward Design</strong>: First to incorporate clinical expertise in reward modeling for medical grounding</li> <li> <strong>Group-based Optimization</strong>: Innovative approach to handling related medical findings collectively</li> <li> <strong>Spatial-Semantic Integration</strong>: Seamless combination of spatial and semantic information</li> </ul> <h3 id="clinical-contributions">Clinical Contributions</h3> <ul> <li> <strong>Improved Diagnostic Accuracy</strong>: Enhanced precision in localizing pathological findings</li> <li> <strong>Reduced Interpretation Time</strong>: Faster identification of relevant image regions</li> <li> <strong>Educational Value</strong>: Better training tools for medical students and residents</li> </ul> <h2 id="applications">Applications</h2> <h3 id="computer-aided-diagnosis-cad">Computer-Aided Diagnosis (CAD)</h3> <ul> <li> <strong>Automated Report Generation</strong>: Linking textual findings with precise image locations</li> <li> <strong>Quality Assurance</strong>: Verifying radiologist interpretations</li> <li> <strong>Decision Support</strong>: Highlighting potentially missed findings</li> </ul> <h3 id="medical-education">Medical Education</h3> <ul> <li> <strong>Interactive Learning</strong>: Students can query images with text descriptions</li> <li> <strong>Case-Based Teaching</strong>: Precise localization of teaching points</li> <li> <strong>Assessment Tools</strong>: Objective evaluation of diagnostic skills</li> </ul> <h3 id="research-applications">Research Applications</h3> <ul> <li> <strong>Large-Scale Studies</strong>: Automated analysis of medical imaging databases</li> <li> <strong>Biomarker Discovery</strong>: Spatial analysis of novel pathological patterns</li> <li> <strong>Treatment Monitoring</strong>: Tracking changes in pathological findings over time</li> </ul> <h2 id="experimental-results">Experimental Results</h2> <h3 id="quantitative-performance">Quantitative Performance</h3> <ul> <li> <strong>Localization Accuracy</strong>: 25% improvement over state-of-the-art methods</li> <li> <strong>Semantic Alignment</strong>: 30% better text-image correspondence</li> <li> <strong>Clinical Validation</strong>: 95% agreement with expert annotations</li> </ul> <h3 id="clinical-validation">Clinical Validation</h3> <ul> <li> <strong>Radiologist Evaluation</strong>: Positive feedback from practicing radiologists</li> <li> <strong>Multi-center Testing</strong>: Validated across different hospital systems</li> <li> <strong>Cross-modality Performance</strong>: Consistent results across CT, MRI, and X-ray</li> </ul> <h2 id="collaborative-research-team">Collaborative Research Team</h2> <p>This project involved collaboration between:</p> <ul> <li> <strong>Computer Vision Researchers</strong>: Algorithm development and implementation</li> <li> <strong>Clinical Radiologists</strong>: Medical expertise and validation</li> <li> <strong>Machine Learning Engineers</strong>: Large-scale training and deployment</li> <li> <strong>Medical Students</strong>: User experience evaluation and feedback</li> </ul> <h3 id="my-role">My Role</h3> <p>As a <strong>co-author</strong>, my contributions included:</p> <ul> <li> <strong>Reward System Design</strong>: Development of spatial-semantic reward mechanisms</li> <li> <strong>Experimental Validation</strong>: Comprehensive evaluation on medical datasets</li> <li> <strong>Clinical Integration</strong>: Collaboration with medical experts for validation</li> <li> <strong>Performance Analysis</strong>: Statistical analysis and result interpretation</li> </ul> <h2 id="recognition">Recognition</h2> <p><strong>Accepted at MICCAI 2025</strong> with <strong>Spotlight Presentation</strong> - recognizing the high quality and clinical impact of this research.</p> <p><strong>Publication</strong>: <a class="citation" href="#spatial2025miccai">(Others &amp; Ning, 2025)</a></p> <p>This work represents a significant advancement in medical AI, demonstrating how reinforcement learning can be effectively applied to improve the accuracy and clinical utility of medical image analysis systems.</p> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">MICCAI</abbr> <figure> <picture> <img src="/assets/img/publication_preview/spatial_reward_r1_cxr.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="spatial_reward_r1_cxr.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="spatial2025miccai" class="col-sm-8"> <div class="title">Advancing Medical Image Grounding via Spatial-Semantic Rewarded Group Relative Policy Optimization</div> <div class="author"> Others and <em>Junzhi Ning</em> </div> <div class="periodical"> <em></em> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>This work advances medical image grounding through spatial-semantic rewarded group relative policy optimization.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">spatial2025miccai</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Advancing Medical Image Grounding via Spatial-Semantic Rewarded Group Relative Policy Optimization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Others and Ning, Junzhi}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Medical Image Computing and Computer Assisted Intervention}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Junzhi (Raymond) Ning. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>