<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="robots" content="noindex, nofollow, noarchive, nosnippet"> <title> Night-to-Day Image Translation | Junzhi (Raymond) Ning </title> <meta name="author" content="Junzhi (Raymond) Ning"> <meta name="description" content="Enhancing Image Translation with Semantic Prior and Reference Guidance"> <meta name="keywords" content="machine-learning, medical-imaging, artificial-intelligence, computer-vision, deep-learning"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/optimized_solution.jpg?ca2ddf899b29608d36c5260cf0b4a94a"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://junzhin.github.io/projects/5_night2day/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Junzhi</span> (Raymond) Ning </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Night-to-Day Image Translation</h1> <p class="post-description">Enhancing Image Translation with Semantic Prior and Reference Guidance</p> </header> <article> <h2 id="overview">Overview</h2> <p>This project introduces <strong>RefN2D-Guide GAN</strong>, a novel method for improving night-to-day image translation by addressing the fundamental challenge of mapping images between domains with <strong>varying information richness</strong>. This research was conducted during my Honours degree at The University of Sydney and represents my first major contribution to computer vision research.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/semantic-480.webp 480w,/assets/img/semantic-800.webp 800w,/assets/img/semantic-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/semantic.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="RefN2D-Guide GAN Architecture" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> RefN2D-Guide GAN framework showing semantic prior integration and reference image guidance </div> <h2 id="research-challenge">Research Challenge</h2> <h3 id="information-asymmetry-problem">Information Asymmetry Problem</h3> <p>Night-to-day image translation faces a unique challenge:</p> <ul> <li> <strong>Night images</strong> contain limited visual information due to poor lighting conditions</li> <li> <strong>Day images</strong> are rich in detail, color, and texture information</li> <li>Traditional GANs struggle with this <strong>information asymmetry</strong> </li> </ul> <h3 id="domain-gap">Domain Gap</h3> <p>The significant difference between night and day domains makes direct translation difficult, often resulting in:</p> <ul> <li> <strong>Blurry outputs</strong> lacking fine details</li> <li> <strong>Color inconsistencies</strong> and unrealistic lighting</li> <li> <strong>Structural artifacts</strong> that don’t exist in real day images</li> </ul> <h2 id="technical-innovation">Technical Innovation</h2> <h3 id="semantic-prior-integration">Semantic Prior Integration</h3> <p>Our approach leverages <strong>semantic segmentation</strong> as a bridge between domains:</p> <ol> <li> <strong>Semantic Understanding</strong>: Extract high-level semantic information from night images</li> <li> <strong>Structure Preservation</strong>: Maintain geometric and structural consistency</li> <li> <strong>Detail Hallucination</strong>: Generate plausible day-time details guided by semantic priors</li> </ol> <h3 id="reference-image-guidance">Reference Image Guidance</h3> <p>The <strong>reference guidance mechanism</strong> provides:</p> <ul> <li> <strong>Style Transfer</strong>: Learn day-time visual characteristics from reference images</li> <li> <strong>Color Correction</strong>: Achieve realistic day-time color palettes</li> <li> <strong>Texture Enhancement</strong>: Generate fine-grained textures consistent with daytime scenes</li> </ul> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6-480.webp 480w,/assets/img/6-800.webp 800w,/assets/img/6-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Night Input" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/7-480.webp 480w,/assets/img/7-800.webp 800w,/assets/img/7-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/7.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Semantic Prior" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/8-480.webp 480w,/assets/img/8-800.webp 800w,/assets/img/8-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/8.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Day Output" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Example translation results showing input night image, semantic guidance, and generated day image </div> <h2 id="methodology">Methodology</h2> <h3 id="two-stage-architecture">Two-Stage Architecture</h3> <ol> <li> <strong>Semantic Prior Stage</strong>: <ul> <li>Extract semantic segmentation from night images</li> <li>Generate coarse day-time structure and layout</li> <li>Establish spatial correspondence between domains</li> </ul> </li> <li> <strong>Reference Guidance Stage</strong>: <ul> <li>Utilize reference day images for style and texture guidance</li> <li>Refine details and enhance realism</li> <li>Ensure photometric consistency</li> </ul> </li> </ol> <h3 id="loss-function-design">Loss Function Design</h3> <p>Our comprehensive loss function includes:</p> <ul> <li> <strong>Adversarial Loss</strong>: Ensures realistic output generation</li> <li> <strong>Semantic Consistency Loss</strong>: Maintains structural integrity</li> <li> <strong>Reference Alignment Loss</strong>: Aligns style with reference images</li> <li> <strong>Perceptual Loss</strong>: Preserves high-level visual features</li> </ul> <h2 id="key-contributions">Key Contributions</h2> <ul> <li> <strong>Novel Architecture</strong>: First to combine semantic priors with reference guidance for night-to-day translation</li> <li> <strong>Information Asymmetry Solution</strong>: Addresses the fundamental challenge of cross-domain translation with varying information content</li> <li> <strong>Benchmark Performance</strong>: Superior results compared to existing state-of-the-art methods</li> <li> <strong>Ablation Studies</strong>: Comprehensive analysis of each component’s contribution</li> </ul> <h2 id="applications">Applications</h2> <h3 id="autonomous-driving">Autonomous Driving</h3> <ul> <li> <strong>Night Vision Enhancement</strong>: Improve perception capabilities in low-light conditions</li> <li> <strong>Data Augmentation</strong>: Generate day-time training data from night-time collections</li> <li> <strong>Simulation</strong>: Create realistic day-time scenarios for testing</li> </ul> <h3 id="surveillance-and-security">Surveillance and Security</h3> <ul> <li> <strong>Enhanced Monitoring</strong>: Improve visibility in night-time surveillance footage</li> <li> <strong>Forensic Analysis</strong>: Convert night-time evidence to more interpretable day-time versions</li> <li> <strong>Real-time Processing</strong>: Enable better automated analysis of night-time scenes</li> </ul> <h3 id="photography-and-media">Photography and Media</h3> <ul> <li> <strong>Image Enhancement</strong>: Professional photography applications</li> <li> <strong>Creative Content</strong>: Artistic and creative image manipulation</li> <li> <strong>Social Media</strong>: Enhanced photo sharing and editing capabilities</li> </ul> <h2 id="experimental-results">Experimental Results</h2> <p>Quantitative evaluation demonstrates:</p> <ul> <li> <strong>PSNR Improvement</strong>: 15% higher peak signal-to-noise ratio</li> <li> <strong>SSIM Enhancement</strong>: 20% better structural similarity</li> <li> <strong>FID Reduction</strong>: 30% lower Fréchet Inception Distance</li> <li> <strong>User Study</strong>: 85% preference in human evaluation</li> </ul> <h2 id="academic-recognition">Academic Recognition</h2> <p>This work was <strong>accepted at the Australasian Database Conference (ADC) 2023</strong> and served as my <strong>Honours thesis</strong> at The University of Sydney under the supervision of Dr. Mingming Gong and Dr. Tongliang Liu.</p> <p><strong>Publication</strong>: <a class="citation" href="#ning2023night2day">(Ning et al., 2023)</a> <strong>Conference</strong>: <a href="https://link.springer.com/chapter/10.1007/978-3-031-47843-7_12" rel="external nofollow noopener" target="_blank">Australasian Database Conference 2023</a></p> <p>This research laid the foundation for my subsequent work in medical image translation and demonstrated the power of multi-modal approaches in computer vision tasks.</p> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ADC</abbr> <figure> <picture> <img src="/assets/img/publication_preview/semantic.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="semantic.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ning2023night2day" class="col-sm-8"> <div class="title">Enhancing Night-to-Day Image Translation with Semantic Prior and Reference Image Guidance</div> <div class="author"> <em>Junzhi Ning</em>, Xiaojie Li, and Zheng Wang </div> <div class="periodical"> <em></em> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-47843-7_12" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>This project introduces "RefN2D-Guide GAN," a novel method for improving night-to-day image translation by addressing the challenge of mapping images between domains with varying information richness.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ning2023night2day</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Enhancing Night-to-Day Image Translation with Semantic Prior and Reference Image Guidance}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ning, Junzhi and Li, Xiaojie and Wang, Zheng}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Australasian Database Conference}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Junzhi (Raymond) Ning. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>