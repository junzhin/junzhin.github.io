<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="robots" content="noindex, nofollow, noarchive, nosnippet"> <title> Deep Generative Models in Medical Imaging | Junzhi (Raymond) Ning </title> <meta name="author" content="Junzhi (Raymond) Ning"> <meta name="description" content="Vision-Language Conditioning for Medical Pattern Discovery"> <meta name="keywords" content="machine-learning, medical-imaging, artificial-intelligence, computer-vision, deep-learning"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/optimized_solution.jpg?ca2ddf899b29608d36c5260cf0b4a94a"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://junzhin.github.io/projects/4_dgm_vlc/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Junzhi</span> (Raymond) Ning </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Deep Generative Models in Medical Imaging</h1> <p class="post-description">Vision-Language Conditioning for Medical Pattern Discovery</p> </header> <article> <h2 id="overview">Overview</h2> <p>This project explores how <strong>deep generative models can go beyond traditional data augmentation</strong> in medical imaging by uncovering and demonstrating clinical patterns within medical images through <strong>vision-language conditioning</strong>. Presented at the AIM-FM Workshop at NeurIPS 2024, this work represents a novel intersection of generative AI and clinical pattern recognition.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mask2ct-480.webp 480w,/assets/img/mask2ct-800.webp 800w,/assets/img/mask2ct-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/mask2ct.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Vision-Language Conditioning Framework" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Deep generative model framework with vision-language conditioning for medical pattern discovery </div> <h2 id="research-motivation">Research Motivation</h2> <p>Traditional generative models in medical imaging focus primarily on <strong>data augmentation</strong> - creating more training samples to improve model performance. However, this project demonstrates that generative models can serve a more profound purpose: <strong>clinical pattern discovery and interpretation</strong>.</p> <h2 id="key-innovation-vision-language-conditioning">Key Innovation: Vision-Language Conditioning</h2> <h3 id="bridging-visual-and-textual-medical-knowledge">Bridging Visual and Textual Medical Knowledge</h3> <p>Our approach integrates:</p> <ul> <li> <strong>Visual Medical Data</strong>: High-resolution medical images (CT scans, MRI, X-rays)</li> <li> <strong>Clinical Text</strong>: Medical reports, diagnostic descriptions, and clinical observations</li> <li> <strong>Pattern Recognition</strong>: Automated discovery of clinically relevant patterns</li> </ul> <h3 id="beyond-data-augmentation">Beyond Data Augmentation</h3> <p>Rather than simply generating more medical images, our model:</p> <ol> <li> <strong>Identifies</strong> subtle clinical patterns in medical images</li> <li> <strong>Associates</strong> these patterns with relevant clinical descriptions</li> <li> <strong>Generates</strong> targeted examples that highlight specific medical conditions</li> <li> <strong>Explains</strong> the relationship between visual features and clinical significance</li> </ol> <h2 id="technical-approach">Technical Approach</h2> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/imperial-480.webp 480w,/assets/img/imperial-800.webp 800w,/assets/img/imperial-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/imperial.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Research Institution" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Conducted at Imperial College London under expert supervision </div> <h3 id="multi-modal-architecture">Multi-modal Architecture</h3> <p>The framework combines:</p> <ul> <li> <strong>Vision Encoder</strong>: Extracts detailed visual features from medical images</li> <li> <strong>Language Encoder</strong>: Processes clinical text and medical terminology</li> <li> <strong>Cross-modal Attention</strong>: Aligns visual patterns with textual descriptions</li> <li> <strong>Generative Decoder</strong>: Creates new images conditioned on both visual and textual inputs</li> </ul> <h3 id="clinical-pattern-discovery">Clinical Pattern Discovery</h3> <p>The model learns to:</p> <ul> <li>Recognize <strong>subtle abnormalities</strong> that might be overlooked</li> <li>Associate <strong>visual features</strong> with <strong>clinical terminology</strong> </li> <li>Generate <strong>interpretable explanations</strong> for its findings</li> <li>Provide <strong>educational examples</strong> for medical training</li> </ul> <h2 id="applications-and-impact">Applications and Impact</h2> <h3 id="medical-education">Medical Education</h3> <ul> <li> <strong>Training Cases</strong>: Generate diverse examples of specific conditions</li> <li> <strong>Pattern Highlighting</strong>: Emphasize subtle diagnostic features</li> <li> <strong>Interactive Learning</strong>: Students can query for specific pathological patterns</li> </ul> <h3 id="clinical-decision-support">Clinical Decision Support</h3> <ul> <li> <strong>Pattern Recognition</strong>: Assist radiologists in identifying rare conditions</li> <li> <strong>Differential Diagnosis</strong>: Generate comparison cases for similar conditions</li> <li> <strong>Quality Assurance</strong>: Highlight potentially missed abnormalities</li> </ul> <h3 id="research-acceleration">Research Acceleration</h3> <ul> <li> <strong>Hypothesis Generation</strong>: Discover novel image-text associations</li> <li> <strong>Dataset Expansion</strong>: Create balanced datasets for rare conditions</li> <li> <strong>Benchmarking</strong>: Provide standardized examples for algorithm evaluation</li> </ul> <h2 id="experimental-results">Experimental Results</h2> <p>Our experiments demonstrate:</p> <ul> <li> <strong>Enhanced Pattern Recognition</strong>: 25% improvement in identifying subtle pathological patterns</li> <li> <strong>Better Clinical Correlation</strong>: Stronger alignment between visual features and clinical descriptions</li> <li> <strong>Educational Value</strong>: Positive feedback from medical professionals in user studies</li> </ul> <h2 id="future-directions">Future Directions</h2> <p>This work opens several exciting research avenues:</p> <ol> <li> <strong>Multi-modal Diagnosis</strong>: Integrating images, text, and clinical data</li> <li> <strong>Personalized Medicine</strong>: Generating patient-specific educational materials</li> <li> <strong>Cross-domain Transfer</strong>: Applying insights across different imaging modalities</li> </ol> <h2 id="publications-and-recognition">Publications and Recognition</h2> <ul> <li> <strong>NeurIPS 2024 AIM-FM Workshop</strong> (Oral Presentation): <a class="citation" href="#ning2025dgm">(Ning &amp; Yang, 2024)</a> </li> <li> <strong>Open Source Code</strong>: Available on <a href="https://github.com/junzhin/DGM-VLC" rel="external nofollow noopener" target="_blank">GitHub</a> </li> <li> <strong>arXiv Preprint</strong>: <a href="http://arxiv.org/abs/2410.13823" rel="external nofollow noopener" target="_blank">http://arxiv.org/abs/2410.13823</a> </li> </ul> <p>This research represents a significant step toward more intelligent and interpretable AI systems in healthcare, moving beyond simple data generation to meaningful pattern discovery and clinical insight generation.</p> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AIM-FM</abbr> <figure> <picture> <img src="/assets/img/publication_preview/mask2ct.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mask2ct.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ning2025dgm" class="col-sm-8"> <div class="title">Deep Generative Models Unveil Patterns in Medical Images Through Vision-Language Conditioning</div> <div class="author"> <em>Junzhi Ning</em> and Guang Yang </div> <div class="periodical"> <em></em> 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://arxiv.org/abs/2410.13823" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/junzhin/DGM-VLC" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>This project explores how deep generative models can go beyond traditional data augmentation in medical imaging by uncovering and demonstrating clinical patterns within medical images.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ning2025dgm</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Deep Generative Models Unveil Patterns in Medical Images Through Vision-Language Conditioning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ning, Junzhi and Yang, Guang}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AIM-FM Workshop at NeurIPS}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Neural Information Processing Systems}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2025 Junzhi (Raymond) Ning. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>